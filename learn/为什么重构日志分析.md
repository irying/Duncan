

### 为什么重构日志分析？

背景：日志分析项目主要功能是读取用户行为日志，分析提取出有用数据，用来作为精准推荐项目的数据来源和构建排行榜，有标签排行榜、热门排行榜和作者排行榜。

瓶颈：日志文件容量越来越大，单线程读取分析的线性处理过程只会越来越长。(7月9号的日志处理过程历经5小时)

解决方案：既然单线程处理过程长，那就改成多线程。

​	方案1：基于原先的python架构，换成多线程读取分析。

​	方案2：采用并发优势语言go重构。

结合项目特点继续展开调研，后端项目大体有两种类型：**计算密集型**和**I/O密集型**。

> 计算密集型任务的特点是要进行大量的计算，消耗CPU资源，比如计算圆周率、对视频进行高清解码等等，全靠CPU的运算能力。这种计算密集型任务虽然也可以用多任务完成，但是任务越多，花在任务切换的时间就越多，CPU执行任务的效率就越低，所以，要最高效地利用CPU，计算密集型任务同时进行的数量应当等于CPU的核心数。
>
> 计算密集型任务由于主要消耗CPU资源，因此，代码运行效率至关重要。Python这样的脚本语言运行效率很低，完全不适合计算密集型任务。对于计算密集型任务，最好用C语言编写。
>
> 第二种任务的类型是IO密集型，涉及到网络、磁盘IO的任务都是IO密集型任务，这类任务的特点是CPU消耗很少，任务的大部分时间都在等待IO操作完成（因为IO的速度远远低于CPU和内存的速度）。对于IO密集型任务，任务越多，CPU效率越高，但也有一个限度。常见的大部分任务都是IO密集型任务，比如Web应用。

 

日志分析项目如果分成多线程处理，如果有16个CPU，最简单高效的做法就是将一个文件分成16份，在每个CPU上独立计算。**可以看出项目属于计算密集型，并不需要长时间等待I/O**。

回到两个方案，那就是对比哪个方案更加适合计算密集型。

参考网上大牛廖雪峰的博客，发现方案1并不适合，原因总结如下：

> Python多线程相当于单核多线程，多线程有两个好处：CPU并行，IO并行，单核多线程相当于自断一臂。所以，在Python中，可以使用多线程，但不要指望能有效利用多核。如果一定要通过多线程利用多核，那只能通过C扩展来实现，不过这样就失去了Python简单易用的特点。



再说说方案2，go语言因为其自带的Goroutine（一种协程实现，用户级线程）具有天然的并发处理优势。

除了语言优势之外，还有一个要考虑的是，多线程下的编程，因为要上锁和释放锁，还要时刻注意死锁等情况，会增加代码复杂度和维护成本。go语言除了提供channel去解决锁的问题，也提供了各种常规锁（读写锁、互斥锁）。

我先用常规的多线程写法，也就是上锁再释放锁去编码，发现非常痛苦，痛苦点在于每个新加的数据结构都要带上锁属性去操作；然后我再用channel的方式实现一样的功能，不带锁，可以说是非常愉悦。

 

综上：单从效率和代码维护性上，我选择了方案2，用于解决读写效率瓶颈。

 

 



廖雪峰的博客：[廖雪峰博客](https://link.zhihu.com/?target=https%3A//www.liaoxuefeng.com/wiki/001374738125095c955c1e6d8bb493182103fac9270762a000/001386832360548a6491f20c62d427287739fcfa5d5be1f000) 